{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "821ee1fe-d302-4d10-90df-06710673fad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82de29ff-b44d-40c4-a288-c908cbb8876e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import RMSprop\n",
    "from torch.utils.data import TensorDataset\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e907985b-3ea4-4828-8cce-70e830979386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join two CSV files and prep them for analysis\n",
    "# Stats Data, https://github.com/blnkpagelabs/nflscraPy/releases/tag/Stats\n",
    "# Game Results Data, https://github.com/blnkpagelabs/nflscraPy?tab=readme-ov-file#seasons\n",
    "\n",
    "season_df = pd.read_csv(\"Season-2023.csv\")\n",
    "stats_df = pd.read_csv(\"Stats-2023.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "612716a9-86ad-468e-951a-b4dbe3a7c661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unnecessary columns\n",
    "season_df = season_df.drop(['boxscore_stats_link','tm_nano'], axis=1)\n",
    "stats_df = stats_df.drop(['boxscore_stats_link','nano'], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89f75cfd-fdb7-4022-9376-76bf58fa0268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "season\n",
      "week\n",
      "week_day\n",
      "event_date\n",
      "game_time\n",
      "tm_market\n",
      "tm_name\n",
      "tm_alias\n",
      "tm_alt_market\n",
      "tm_alt_alias\n",
      "opp_nano\n",
      "opp_market\n",
      "opp_name\n",
      "opp_alias\n",
      "opp_alt_market\n",
      "opp_alt_alias\n",
      "tm_location\n",
      "opp_location\n",
      "tm_score\n",
      "opp_score\n"
     ]
    }
   ],
   "source": [
    "# Get the list of column names\n",
    "column_names_season = season_df.columns.tolist()\n",
    "column_names_stats = stats_df.columns.tolist()\n",
    "# Print each column name in separate rows\n",
    "for column_name_season in column_names_season:\n",
    "    print(column_name_season)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d9e5fb6-9463-41ea-b07a-5e5f24977056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "season\n",
      "event_date\n",
      "market\n",
      "name\n",
      "alias\n",
      "rush_att\n",
      "rush_yds\n",
      "rush_tds\n",
      "pass_cmp\n",
      "pass_att\n",
      "pass_cmp_pct\n",
      "pass_yds\n",
      "pass_tds\n",
      "pass_int\n",
      "passer_rating\n",
      "net_pass_yds\n",
      "total_yds\n",
      "times_sacked\n",
      "yds_sacked_for\n",
      "fumbles\n",
      "fumbles_lost\n",
      "turnovers\n",
      "penalties\n",
      "penalty_yds\n",
      "first_downs\n",
      "third_down_conv\n",
      "third_down_att\n",
      "third_down_conv_pct\n",
      "fourth_down_conv\n",
      "fourth_down_att\n",
      "fourth_down_conv_pct\n",
      "time_of_possession\n"
     ]
    }
   ],
   "source": [
    "for column_name_stats in column_names_stats:\n",
    "    print(column_name_stats)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4a5008c-1720-4e1a-a5de-595958e1f411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   status  season  week week_day  event_date game_time      tm_market tm_name  \\\n",
      "0  closed    2023    22      Sun  2024-02-11    6:30PM    Kansas City  Chiefs   \n",
      "1  closed    2023    21      Sun  2024-01-28    6:30PM  San Francisco   49ers   \n",
      "2  closed    2023    21      Sun  2024-01-28    3:00PM    Kansas City  Chiefs   \n",
      "3  closed    2023    20      Sun  2024-01-21    3:00PM        Detroit   Lions   \n",
      "4  closed    2023    20      Sun  2024-01-21    6:30PM    Kansas City  Chiefs   \n",
      "\n",
      "  tm_alias        tm_alt_market tm_alt_alias       opp_nano     opp_market  \\\n",
      "0       KC   kansas-city-chiefs          kan  IwSI92ZDKoazn  San Francisco   \n",
      "1       SF  san-francisco-49ers          sfo  FCuH1wdksA2DQ        Detroit   \n",
      "2       KC   kansas-city-chiefs          kan  zyhFXj1nywrm1      Baltimore   \n",
      "3      DET        detroit-lions          det  QMAZH1v922YLu      Tampa Bay   \n",
      "4       KC   kansas-city-chiefs          kan  3VqeLK0LS9rpw        Buffalo   \n",
      "\n",
      "     opp_name opp_alias        opp_alt_market opp_alt_alias tm_location  \\\n",
      "0       49ers        SF   san-francisco-49ers           sfo           N   \n",
      "1       Lions       DET         detroit-lions           det           H   \n",
      "2      Ravens       BAL      baltimore-ravens           rav           A   \n",
      "3  Buccaneers        TB  tampa-bay-buccaneers           tam           H   \n",
      "4       Bills       BUF         buffalo-bills           buf           A   \n",
      "\n",
      "  opp_location  tm_score  opp_score  \n",
      "0            N        25         22  \n",
      "1            A        34         31  \n",
      "2            H        17         10  \n",
      "3            A        31         23  \n",
      "4            H        27         24  \n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "print(season_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a1d5338-adbe-46d1-8111-d0ca403be2dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   season  event_date         market    name alias  rush_att  rush_yds  \\\n",
      "0    2023  2024-01-28      Baltimore  Ravens   BAL        16        81   \n",
      "1    2023  2024-01-28    Kansas City  Chiefs    KC        32        89   \n",
      "2    2023  2024-01-28  San Francisco   49ers    SF        33       155   \n",
      "3    2023  2024-01-28        Detroit   Lions   DET        29       182   \n",
      "4    2023  2024-01-21    Kansas City  Chiefs    KC        24       146   \n",
      "\n",
      "   rush_tds  pass_cmp  pass_att  pass_cmp_pct  pass_yds  pass_tds  pass_int  \\\n",
      "0         0        20        37         0.541       272         1         1   \n",
      "1         1        30        39         0.769       241         1         0   \n",
      "2         3        20        31         0.645       267         1         1   \n",
      "3         3        25        41         0.610       273         1         0   \n",
      "4         1        17        23         0.739       215         2         0   \n",
      "\n",
      "   passer_rating  net_pass_yds  total_yds  times_sacked  yds_sacked_for  \\\n",
      "0         75.507           255        336             4              17   \n",
      "1        100.481           230        319             2              11   \n",
      "2         89.046           258        413             2               9   \n",
      "3         88.770           260        442             2              13   \n",
      "4        131.612           215        361             0               0   \n",
      "\n",
      "   fumbles  fumbles_lost  turnovers  penalties  penalty_yds  first_downs  \\\n",
      "0        2             2          3          8           95           16   \n",
      "1        2             0          0          3           30           22   \n",
      "2        0             0          1          3           20           23   \n",
      "3        1             1          1          2           15           28   \n",
      "4        2             1          1          2           15           21   \n",
      "\n",
      "   third_down_conv  third_down_att  third_down_conv_pct  fourth_down_conv  \\\n",
      "0                3              11                0.273                 2   \n",
      "1                8              18                0.444                 1   \n",
      "2                6              12                0.500                 0   \n",
      "3                6              12                0.500                 1   \n",
      "4                1               5                0.200                 0   \n",
      "\n",
      "   fourth_down_att  fourth_down_conv_pct  time_of_possession  \n",
      "0                2                 1.000                1350  \n",
      "1                2                 0.500                2250  \n",
      "2                1                 0.000                1932  \n",
      "3                3                 0.333                1668  \n",
      "4                0                 0.000                1377  \n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "print(stats_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70784103-f72b-49fe-8ca9-84ba7aa3fe53",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_aliases_season = season_df['tm_name'].unique().tolist()\n",
    "unique_aliases_stats = stats_df['name'].unique().tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bba3ce6a-8f8f-4ea1-906b-bb88942175f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All values in both lists are the same.\n"
     ]
    }
   ],
   "source": [
    "# Create an empty list to store mismatched values\n",
    "mismatched_values = []\n",
    "\n",
    "# Loop through each value in unique_aliases_season\n",
    "for value in unique_aliases_season:\n",
    "  # Check if the value exists in unique_aliases_stats\n",
    "  if value not in unique_aliases_stats:\n",
    "    # Add the value and its source list (unique_aliases_season) to mismatched_values\n",
    "    mismatched_values.append((value, \"unique_aliases_season\"))\n",
    "\n",
    "# Loop through each value in unique_aliases_stats (opposite direction)\n",
    "for value in unique_aliases_stats:\n",
    "  # Check if the value exists in unique_aliases_season (already checked in first loop)\n",
    "  if value not in unique_aliases_season:\n",
    "    # Add the value and its source list (unique_aliases_stats) to mismatched_values\n",
    "    mismatched_values.append((value, \"unique_aliases_stats\"))\n",
    "\n",
    "# Print the list of mismatched values and their source lists\n",
    "if mismatched_values:\n",
    "  # Print header\n",
    "  print(\"Following values differ between the lists:\")\n",
    "  # Loop through mismatched_values and print each tuple\n",
    "  for value, source in mismatched_values:\n",
    "    print(f\"\\t- {value} (from {source})\")\n",
    "else:\n",
    "  print(\"All values in both lists are the same.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c37f4de-2831-4b2d-96e8-b30ff6237f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   status  season  week week_day  event_date game_time      tm_market tm_name  \\\n",
      "0  closed    2023    22      Sun  2024-02-11    6:30PM    Kansas City  Chiefs   \n",
      "1  closed    2023    21      Sun  2024-01-28    6:30PM  San Francisco   49ers   \n",
      "2  closed    2023    21      Sun  2024-01-28    3:00PM    Kansas City  Chiefs   \n",
      "3  closed    2023    20      Sun  2024-01-21    3:00PM        Detroit   Lions   \n",
      "4  closed    2023    20      Sun  2024-01-21    6:30PM    Kansas City  Chiefs   \n",
      "\n",
      "  tm_alias        tm_alt_market tm_alt_alias       opp_nano     opp_market  \\\n",
      "0       KC   kansas-city-chiefs          kan  IwSI92ZDKoazn  San Francisco   \n",
      "1       SF  san-francisco-49ers          sfo  FCuH1wdksA2DQ        Detroit   \n",
      "2       KC   kansas-city-chiefs          kan  zyhFXj1nywrm1      Baltimore   \n",
      "3      DET        detroit-lions          det  QMAZH1v922YLu      Tampa Bay   \n",
      "4       KC   kansas-city-chiefs          kan  3VqeLK0LS9rpw        Buffalo   \n",
      "\n",
      "     opp_name opp_alias        opp_alt_market opp_alt_alias tm_location  \\\n",
      "0       49ers        SF   san-francisco-49ers           sfo           N   \n",
      "1       Lions       DET         detroit-lions           det           H   \n",
      "2      Ravens       BAL      baltimore-ravens           rav           A   \n",
      "3  Buccaneers        TB  tampa-bay-buccaneers           tam           H   \n",
      "4       Bills       BUF         buffalo-bills           buf           A   \n",
      "\n",
      "  opp_location  tm_score  opp_score  \n",
      "0            N        25         22  \n",
      "1            A        34         31  \n",
      "2            H        17         10  \n",
      "3            A        31         23  \n",
      "4            H        27         24  \n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "print(season_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "959972a9-cae1-4386-acf8-2152bcb17bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Placeholder columns for home/away team stats created.\n"
     ]
    }
   ],
   "source": [
    "#merge the dataframes\n",
    "merged_df = season_df.copy()\n",
    "\n",
    "#create columns in merged_df\n",
    "# Define stat names (assuming they are not present in your data)\n",
    "stat_cols = ['rush_att', 'rush_yds', 'rush_tds', 'pass_cmp', 'pass_att', \n",
    "             'pass_cmp_pct', 'pass_yds', 'pass_tds', 'pass_int', 'passer_rating', \n",
    "             'net_pass_yds', 'total_yds', 'times_sacked', 'yds_sacked_for', \n",
    "             'fumbles', 'fumbles_lost', 'turnovers', 'penalties', 'penalty_yds', \n",
    "             'first_downs', 'third_down_conv', 'third_down_att', 'third_down_conv_pct', \n",
    "             'fourth_down_conv', 'fourth_down_att', 'fourth_down_conv_pct', 'time_of_possession']\n",
    "\n",
    "# Define a dictionary to map stat names to suffixes for home and away teams\n",
    "stat_suffixes = {'_A': 'Away', '_H': 'Home'}\n",
    "\n",
    "# Create new columns with suffixes for home and away teams, filled with NaN initially\n",
    "for stat in stat_cols:\n",
    "  merged_df[stat + '_A'] = np.nan\n",
    "  merged_df[stat + '_H'] = np.nan\n",
    "\n",
    "# Add labels to stat names using the dictionary\n",
    "for stat, suffix in stat_suffixes.items():\n",
    "  merged_df.rename(columns={stat: f\"{suffix} {stat[:-2]}\"}, inplace=True)\n",
    "\n",
    "print(\"Placeholder columns for home/away team stats created.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f8d4fd8-f5af-4794-b8eb-c65e7227d619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   status  season  week week_day  event_date game_time      tm_market tm_name  \\\n",
      "0  closed    2023    22      Sun  2024-02-11    6:30PM    Kansas City  Chiefs   \n",
      "1  closed    2023    21      Sun  2024-01-28    6:30PM  San Francisco   49ers   \n",
      "2  closed    2023    21      Sun  2024-01-28    3:00PM    Kansas City  Chiefs   \n",
      "3  closed    2023    20      Sun  2024-01-21    3:00PM        Detroit   Lions   \n",
      "4  closed    2023    20      Sun  2024-01-21    6:30PM    Kansas City  Chiefs   \n",
      "\n",
      "  tm_alias        tm_alt_market tm_alt_alias       opp_nano     opp_market  \\\n",
      "0       KC   kansas-city-chiefs          kan  IwSI92ZDKoazn  San Francisco   \n",
      "1       SF  san-francisco-49ers          sfo  FCuH1wdksA2DQ        Detroit   \n",
      "2       KC   kansas-city-chiefs          kan  zyhFXj1nywrm1      Baltimore   \n",
      "3      DET        detroit-lions          det  QMAZH1v922YLu      Tampa Bay   \n",
      "4       KC   kansas-city-chiefs          kan  3VqeLK0LS9rpw        Buffalo   \n",
      "\n",
      "     opp_name opp_alias        opp_alt_market opp_alt_alias tm_location  \\\n",
      "0       49ers        SF   san-francisco-49ers           sfo           N   \n",
      "1       Lions       DET         detroit-lions           det           H   \n",
      "2      Ravens       BAL      baltimore-ravens           rav           A   \n",
      "3  Buccaneers        TB  tampa-bay-buccaneers           tam           H   \n",
      "4       Bills       BUF         buffalo-bills           buf           A   \n",
      "\n",
      "  opp_location  tm_score  opp_score  rush_att_A  rush_att_H  rush_yds_A  \\\n",
      "0            N        25         22         NaN         NaN         NaN   \n",
      "1            A        34         31         NaN         NaN         NaN   \n",
      "2            H        17         10         NaN         NaN         NaN   \n",
      "3            A        31         23         NaN         NaN         NaN   \n",
      "4            H        27         24         NaN         NaN         NaN   \n",
      "\n",
      "   rush_yds_H  rush_tds_A  rush_tds_H  pass_cmp_A  pass_cmp_H  pass_att_A  \\\n",
      "0         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "1         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "2         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "3         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "4         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "\n",
      "   pass_att_H  pass_cmp_pct_A  pass_cmp_pct_H  pass_yds_A  pass_yds_H  \\\n",
      "0         NaN             NaN             NaN         NaN         NaN   \n",
      "1         NaN             NaN             NaN         NaN         NaN   \n",
      "2         NaN             NaN             NaN         NaN         NaN   \n",
      "3         NaN             NaN             NaN         NaN         NaN   \n",
      "4         NaN             NaN             NaN         NaN         NaN   \n",
      "\n",
      "   pass_tds_A  pass_tds_H  pass_int_A  pass_int_H  passer_rating_A  \\\n",
      "0         NaN         NaN         NaN         NaN              NaN   \n",
      "1         NaN         NaN         NaN         NaN              NaN   \n",
      "2         NaN         NaN         NaN         NaN              NaN   \n",
      "3         NaN         NaN         NaN         NaN              NaN   \n",
      "4         NaN         NaN         NaN         NaN              NaN   \n",
      "\n",
      "   passer_rating_H  net_pass_yds_A  net_pass_yds_H  total_yds_A  total_yds_H  \\\n",
      "0              NaN             NaN             NaN          NaN          NaN   \n",
      "1              NaN             NaN             NaN          NaN          NaN   \n",
      "2              NaN             NaN             NaN          NaN          NaN   \n",
      "3              NaN             NaN             NaN          NaN          NaN   \n",
      "4              NaN             NaN             NaN          NaN          NaN   \n",
      "\n",
      "   times_sacked_A  times_sacked_H  yds_sacked_for_A  yds_sacked_for_H  \\\n",
      "0             NaN             NaN               NaN               NaN   \n",
      "1             NaN             NaN               NaN               NaN   \n",
      "2             NaN             NaN               NaN               NaN   \n",
      "3             NaN             NaN               NaN               NaN   \n",
      "4             NaN             NaN               NaN               NaN   \n",
      "\n",
      "   fumbles_A  fumbles_H  fumbles_lost_A  fumbles_lost_H  turnovers_A  \\\n",
      "0        NaN        NaN             NaN             NaN          NaN   \n",
      "1        NaN        NaN             NaN             NaN          NaN   \n",
      "2        NaN        NaN             NaN             NaN          NaN   \n",
      "3        NaN        NaN             NaN             NaN          NaN   \n",
      "4        NaN        NaN             NaN             NaN          NaN   \n",
      "\n",
      "   turnovers_H  penalties_A  penalties_H  penalty_yds_A  penalty_yds_H  \\\n",
      "0          NaN          NaN          NaN            NaN            NaN   \n",
      "1          NaN          NaN          NaN            NaN            NaN   \n",
      "2          NaN          NaN          NaN            NaN            NaN   \n",
      "3          NaN          NaN          NaN            NaN            NaN   \n",
      "4          NaN          NaN          NaN            NaN            NaN   \n",
      "\n",
      "   first_downs_A  first_downs_H  third_down_conv_A  third_down_conv_H  \\\n",
      "0            NaN            NaN                NaN                NaN   \n",
      "1            NaN            NaN                NaN                NaN   \n",
      "2            NaN            NaN                NaN                NaN   \n",
      "3            NaN            NaN                NaN                NaN   \n",
      "4            NaN            NaN                NaN                NaN   \n",
      "\n",
      "   third_down_att_A  third_down_att_H  third_down_conv_pct_A  \\\n",
      "0               NaN               NaN                    NaN   \n",
      "1               NaN               NaN                    NaN   \n",
      "2               NaN               NaN                    NaN   \n",
      "3               NaN               NaN                    NaN   \n",
      "4               NaN               NaN                    NaN   \n",
      "\n",
      "   third_down_conv_pct_H  fourth_down_conv_A  fourth_down_conv_H  \\\n",
      "0                    NaN                 NaN                 NaN   \n",
      "1                    NaN                 NaN                 NaN   \n",
      "2                    NaN                 NaN                 NaN   \n",
      "3                    NaN                 NaN                 NaN   \n",
      "4                    NaN                 NaN                 NaN   \n",
      "\n",
      "   fourth_down_att_A  fourth_down_att_H  fourth_down_conv_pct_A  \\\n",
      "0                NaN                NaN                     NaN   \n",
      "1                NaN                NaN                     NaN   \n",
      "2                NaN                NaN                     NaN   \n",
      "3                NaN                NaN                     NaN   \n",
      "4                NaN                NaN                     NaN   \n",
      "\n",
      "   fourth_down_conv_pct_H  time_of_possession_A  time_of_possession_H  \n",
      "0                     NaN                   NaN                   NaN  \n",
      "1                     NaN                   NaN                   NaN  \n",
      "2                     NaN                   NaN                   NaN  \n",
      "3                     NaN                   NaN                   NaN  \n",
      "4                     NaN                   NaN                   NaN  \n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "print(merged_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "304ccca4-18e0-449a-aabd-09b66510a74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "season\n",
      "week\n",
      "week_day\n",
      "event_date\n",
      "game_time\n",
      "tm_market\n",
      "tm_name\n",
      "tm_alias\n",
      "tm_alt_market\n",
      "tm_alt_alias\n",
      "opp_nano\n",
      "opp_market\n",
      "opp_name\n",
      "opp_alias\n",
      "opp_alt_market\n",
      "opp_alt_alias\n",
      "tm_location\n",
      "opp_location\n",
      "tm_score\n",
      "opp_score\n",
      "rush_att_A\n",
      "rush_att_H\n",
      "rush_yds_A\n",
      "rush_yds_H\n",
      "rush_tds_A\n",
      "rush_tds_H\n",
      "pass_cmp_A\n",
      "pass_cmp_H\n",
      "pass_att_A\n",
      "pass_att_H\n",
      "pass_cmp_pct_A\n",
      "pass_cmp_pct_H\n",
      "pass_yds_A\n",
      "pass_yds_H\n",
      "pass_tds_A\n",
      "pass_tds_H\n",
      "pass_int_A\n",
      "pass_int_H\n",
      "passer_rating_A\n",
      "passer_rating_H\n",
      "net_pass_yds_A\n",
      "net_pass_yds_H\n",
      "total_yds_A\n",
      "total_yds_H\n",
      "times_sacked_A\n",
      "times_sacked_H\n",
      "yds_sacked_for_A\n",
      "yds_sacked_for_H\n",
      "fumbles_A\n",
      "fumbles_H\n",
      "fumbles_lost_A\n",
      "fumbles_lost_H\n",
      "turnovers_A\n",
      "turnovers_H\n",
      "penalties_A\n",
      "penalties_H\n",
      "penalty_yds_A\n",
      "penalty_yds_H\n",
      "first_downs_A\n",
      "first_downs_H\n",
      "third_down_conv_A\n",
      "third_down_conv_H\n",
      "third_down_att_A\n",
      "third_down_att_H\n",
      "third_down_conv_pct_A\n",
      "third_down_conv_pct_H\n",
      "fourth_down_conv_A\n",
      "fourth_down_conv_H\n",
      "fourth_down_att_A\n",
      "fourth_down_att_H\n",
      "fourth_down_conv_pct_A\n",
      "fourth_down_conv_pct_H\n",
      "time_of_possession_A\n",
      "time_of_possession_H\n"
     ]
    }
   ],
   "source": [
    "# Get the list of column names\n",
    "column_names_season = merged_df.columns.tolist()\n",
    "# Print each column name in separate rows\n",
    "for column_name_season in column_names_season:\n",
    "    print(column_name_season)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23971e11-7958-43ba-ba6e-dbfc7c40b1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of columns to update\n",
    "columns_to_update = ['rush_att', 'rush_yds', 'rush_tds', 'pass_cmp', 'pass_att', 'pass_cmp_pct', 'pass_yds', 'pass_tds', 'pass_int', 'passer_rating', 'net_pass_yds', 'total_yds', 'times_sacked', 'yds_sacked_for', 'fumbles', 'fumbles_lost', 'turnovers', 'penalties', 'penalty_yds', 'first_downs', 'third_down_conv', 'third_down_att', 'third_down_conv_pct', 'fourth_down_conv', 'fourth_down_att', 'fourth_down_conv_pct', 'time_of_possession']\n",
    "\n",
    "# Merge and update data for 'tm_name'\n",
    "merged_df_tm = merged_df.merge(stats_df, left_on=['event_date', 'tm_name'], right_on=['event_date', 'name'], how='left', suffixes=('', '_tm'))\n",
    "for column in columns_to_update:\n",
    "    if column in merged_df_tm.columns:\n",
    "        merged_df.loc[merged_df['tm_location'] == 'H', f\"{column}_H\"] = merged_df_tm.loc[merged_df['tm_location'] == 'H', column]\n",
    "        merged_df.loc[merged_df['tm_location'] == 'A', f\"{column}_A\"] = merged_df_tm.loc[merged_df['tm_location'] == 'A', column]\n",
    "\n",
    "# Merge and update data for 'opp_name'\n",
    "merged_df_opp = merged_df.merge(stats_df, left_on=['event_date', 'opp_name'], right_on=['event_date', 'name'], how='left', suffixes=('', '_opp'))\n",
    "for column in columns_to_update:\n",
    "    if column in merged_df_opp.columns:\n",
    "        merged_df.loc[merged_df['opp_location'] == 'H', f\"{column}_H\"] = merged_df_opp.loc[merged_df['opp_location'] == 'H', column]\n",
    "        merged_df.loc[merged_df['opp_location'] == 'A', f\"{column}_A\"] = merged_df_opp.loc[merged_df['opp_location'] == 'A', column]\n",
    "\n",
    "# Create a list of columns to drop, skipping the ones that don't exist\n",
    "columns_to_drop = [f\"{column}_tm\" for column in columns_to_update if f\"{column}_tm\" in merged_df_tm.columns]\n",
    "columns_to_drop.extend([f\"{column}_opp\" for column in columns_to_update if f\"{column}_opp\" in merged_df_opp.columns])\n",
    "if 'name_tm' in merged_df_tm.columns:\n",
    "    columns_to_drop.append('name_tm')\n",
    "if 'name_opp' in merged_df_opp.columns:\n",
    "    columns_to_drop.append('name_opp')\n",
    "\n",
    "# Drop the unnecessary columns from merged_df\n",
    "merged_df = merged_df.drop(columns=[col for col in columns_to_drop if col in merged_df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fedd169a-2917-4807-abad-51ba1c4b7932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a location column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7458602e-b297-4e55-83dc-8235b3f4e8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created column 'tot_plays_A' for total plays (Away team).\n",
      "Created column 'tot_plays_H' for total plays (Home team).\n",
      "Created column 'total_yds_per_play_A' for total yards per play (_A team).\n",
      "Created column 'total_yds_per_play_H' for total yards per play (_H team).\n"
     ]
    }
   ],
   "source": [
    "# create more features and fill in pass completion rate if missing\n",
    "# calculate pass completion rate\n",
    "merged_df.loc[merged_df['pass_cmp_pct_A'].isna(), 'pass_cmp_pct_A'] = merged_df['pass_cmp_A'] / merged_df['pass_att_A']\n",
    "merged_df.loc[merged_df['pass_cmp_pct_H'].isna(), 'pass_cmp_pct_H'] = merged_df['pass_cmp_H'] / merged_df['pass_att_H']\n",
    "\n",
    "# Define a dictionary to map column name suffixes to team names\n",
    "team_suffixes = {'_A': 'Away', '_H': 'Home'}\n",
    "\n",
    "# Iterate through team suffixes (A and H)\n",
    "for suffix, team_name in team_suffixes.items():\n",
    "  # Create the new column name for total plays\n",
    "  tot_plays_col = f\"tot_plays{suffix}\"\n",
    "\n",
    "  # Calculate the sum of rush attempts and pass attempts using string formatting\n",
    "  merged_df[tot_plays_col] = merged_df[f'rush_att{suffix}'] + merged_df[f'pass_att{suffix}']\n",
    "\n",
    "  # Print a message for clarity\n",
    "  print(f\"Created column '{tot_plays_col}' for total plays ({team_name} team).\")\n",
    "\n",
    "# Avoid division by zero errors with try-except blocks and handle potential missing data\n",
    "for team_suffix in ('_A', '_H'):\n",
    "  tot_plays_col = f\"tot_plays{team_suffix}\"\n",
    "  total_yds_col = f\"total_yds{team_suffix}\"\n",
    "  new_col_name = f\"total_yds_per_play{team_suffix}\"\n",
    "\n",
    "  try:\n",
    "    # Calculate total yards per play (handling division by zero)\n",
    "    merged_df[new_col_name] = np.where(merged_df[tot_plays_col] > 0, \n",
    "                                       merged_df[total_yds_col] / merged_df[tot_plays_col], \n",
    "                                       np.nan)\n",
    "    print(f\"Created column '{new_col_name}' for total yards per play ({team_suffix} team).\")\n",
    "  except KeyError:\n",
    "    print(f\"Error: Columns 'tot_plays{team_suffix}' or 'total_yds{team_suffix}' might be missing.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef292de1-85ef-4528-b37a-e1ddeda83f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Missing or invalid 'opp_location' value for row 0. Points not assigned.\n"
     ]
    }
   ],
   "source": [
    "# convert tm_score and opp_score to points_A and points_H\n",
    "merged_df['points_A'] = np.nan\n",
    "merged_df['points_H'] = np.nan\n",
    "\n",
    "# Define new column names for points\n",
    "points_cols = {'H': 'points_H', 'A': 'points_A'}\n",
    "\n",
    "# Iterate through rows in merged_df\n",
    "for index, row in merged_df.iterrows():\n",
    "  # Extract tm_location \n",
    "  tm_location = row.get('tm_location')\n",
    "\n",
    "  # Check if tm_location exists and assign points based on location (if possible)\n",
    "  if tm_location in points_cols:\n",
    "    merged_df.at[index, points_cols[tm_location]] = row['tm_score']\n",
    "  else:\n",
    "    # Handle cases where tm_location is missing or not 'H' or 'A' (optional)\n",
    "    pass\n",
    "\n",
    "  # Repeat for opponent's location \n",
    "  opp_location = row.get('opp_location')\n",
    "  if opp_location in points_cols:\n",
    "    merged_df.at[index, points_cols[opp_location]] = row['opp_score']\n",
    "  else:\n",
    "    # Handle cases where opp_location is missing or not 'H' or 'A' (optional)\n",
    "    print(f\"Warning: Missing or invalid 'opp_location' value for row {index}. Points not assigned.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1fddc3d7-1960-4559-b662-96cc56fec143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   status  season  week week_day  event_date game_time      tm_market  \\\n",
      "0  closed    2023    22      Sun  2024-02-11    6:30PM    Kansas City   \n",
      "1  closed    2023    21      Sun  2024-01-28    6:30PM  San Francisco   \n",
      "2  closed    2023    21      Sun  2024-01-28    3:00PM    Kansas City   \n",
      "3  closed    2023    20      Sun  2024-01-21    3:00PM        Detroit   \n",
      "4  closed    2023    20      Sun  2024-01-21    6:30PM    Kansas City   \n",
      "5  closed    2023    20      Sat  2024-01-20    8:15PM  San Francisco   \n",
      "6  closed    2023    20      Sat  2024-01-20    4:30PM      Baltimore   \n",
      "7  closed    2023    19      Mon  2024-01-15    8:15PM      Tampa Bay   \n",
      "8  closed    2023    19      Mon  2024-01-15    4:30PM        Buffalo   \n",
      "9  closed    2023    19      Sun  2024-01-14    8:15PM        Detroit   \n",
      "\n",
      "      tm_name tm_alias         tm_alt_market tm_alt_alias       opp_nano  \\\n",
      "0      Chiefs       KC    kansas-city-chiefs          kan  IwSI92ZDKoazn   \n",
      "1       49ers       SF   san-francisco-49ers          sfo  FCuH1wdksA2DQ   \n",
      "2      Chiefs       KC    kansas-city-chiefs          kan  zyhFXj1nywrm1   \n",
      "3       Lions      DET         detroit-lions          det  QMAZH1v922YLu   \n",
      "4      Chiefs       KC    kansas-city-chiefs          kan  3VqeLK0LS9rpw   \n",
      "5       49ers       SF   san-francisco-49ers          sfo  D5QY6bOxfn8ZL   \n",
      "6      Ravens      BAL      baltimore-ravens          rav  UI0Ax4HUEXFh6   \n",
      "7  Buccaneers       TB  tampa-bay-buccaneers          tam  hjjmgzxilGWdr   \n",
      "8       Bills      BUF         buffalo-bills          buf  SlVgURDFI7EXX   \n",
      "9       Lions      DET         detroit-lions          det  u98I1lDKQBwZ0   \n",
      "\n",
      "      opp_market    opp_name opp_alias        opp_alt_market opp_alt_alias  \\\n",
      "0  San Francisco       49ers        SF   san-francisco-49ers           sfo   \n",
      "1        Detroit       Lions       DET         detroit-lions           det   \n",
      "2      Baltimore      Ravens       BAL      baltimore-ravens           rav   \n",
      "3      Tampa Bay  Buccaneers        TB  tampa-bay-buccaneers           tam   \n",
      "4        Buffalo       Bills       BUF         buffalo-bills           buf   \n",
      "5      Green Bay     Packers        GB     green-bay-packers           gnb   \n",
      "6        Houston      Texans       HOU        houston-texans           htx   \n",
      "7   Philadelphia      Eagles       PHI   philadelphia-eagles           phi   \n",
      "8     Pittsburgh    Steelers       PIT   pittsburgh-steelers           pit   \n",
      "9    Los Angeles        Rams        LA      los-angeles-rams           ram   \n",
      "\n",
      "  tm_location opp_location  tm_score  opp_score  rush_att_A  rush_att_H  \\\n",
      "0           N            N        25         22         NaN         NaN   \n",
      "1           H            A        34         31        29.0        33.0   \n",
      "2           A            H        17         10        32.0        16.0   \n",
      "3           H            A        31         23        15.0        26.0   \n",
      "4           A            H        27         24        24.0        39.0   \n",
      "5           H            A        24         21        28.0        24.0   \n",
      "6           H            A        34         10        14.0        42.0   \n",
      "7           H            A        32          9        15.0        29.0   \n",
      "8           H            A        31         17        23.0        34.0   \n",
      "9           H            A        24         23        17.0        25.0   \n",
      "\n",
      "   rush_yds_A  rush_yds_H  rush_tds_A  rush_tds_H  pass_cmp_A  pass_cmp_H  \\\n",
      "0         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "1       182.0       155.0         3.0         3.0        25.0        20.0   \n",
      "2        89.0        81.0         1.0         0.0        30.0        20.0   \n",
      "3        89.0       114.0         0.0         2.0        26.0        30.0   \n",
      "4       146.0       182.0         1.0         2.0        17.0        26.0   \n",
      "5       136.0       111.0         0.0         2.0        21.0        23.0   \n",
      "6        38.0       229.0         0.0         2.0        19.0        16.0   \n",
      "7        42.0       119.0         0.0         0.0        25.0        22.0   \n",
      "8       106.0       179.0         0.0         1.0        22.0        21.0   \n",
      "9        68.0        79.0         0.0         2.0        25.0        22.0   \n",
      "\n",
      "   pass_att_A  pass_att_H  pass_cmp_pct_A  pass_cmp_pct_H  pass_yds_A  \\\n",
      "0         NaN         NaN             NaN             NaN         NaN   \n",
      "1        41.0        31.0           0.610           0.645       273.0   \n",
      "2        39.0        37.0           0.769           0.541       241.0   \n",
      "3        41.0        43.0           0.634           0.698       349.0   \n",
      "4        23.0        39.0           0.739           0.667       215.0   \n",
      "5        34.0        39.0           0.618           0.590       194.0   \n",
      "6        33.0        22.0           0.576           0.727       175.0   \n",
      "7        35.0        36.0           0.714           0.611       250.0   \n",
      "8        39.0        30.0           0.564           0.700       229.0   \n",
      "9        36.0        27.0           0.694           0.815       367.0   \n",
      "\n",
      "   pass_yds_H  pass_tds_A  pass_tds_H  pass_int_A  pass_int_H  \\\n",
      "0         NaN         NaN         NaN         NaN         NaN   \n",
      "1       267.0         1.0         1.0         0.0         1.0   \n",
      "2       272.0         1.0         1.0         0.0         1.0   \n",
      "3       287.0         3.0         2.0         2.0         0.0   \n",
      "4       186.0         2.0         1.0         0.0         0.0   \n",
      "5       252.0         2.0         1.0         2.0         0.0   \n",
      "6       152.0         0.0         2.0         0.0         0.0   \n",
      "7       337.0         1.0         3.0         0.0         0.0   \n",
      "8       203.0         2.0         3.0         1.0         0.0   \n",
      "9       277.0         2.0         1.0         0.0         0.0   \n",
      "\n",
      "   passer_rating_A  passer_rating_H  net_pass_yds_A  net_pass_yds_H  \\\n",
      "0              NaN              NaN             NaN             NaN   \n",
      "1           88.770           89.046           260.0           258.0   \n",
      "2          100.481           75.507           230.0           255.0   \n",
      "3           94.461          103.537           319.0           277.0   \n",
      "4          131.612           86.058           215.0           186.0   \n",
      "5           72.426           86.699           194.0           245.0   \n",
      "6           72.159          121.780           175.0           123.0   \n",
      "7          100.893          119.792           234.0           307.0   \n",
      "8           79.968          121.944           218.0           189.0   \n",
      "9          120.949          121.759           357.0           255.0   \n",
      "\n",
      "   total_yds_A  total_yds_H  times_sacked_A  times_sacked_H  yds_sacked_for_A  \\\n",
      "0          NaN          NaN             NaN             NaN               NaN   \n",
      "1        442.0        413.0             2.0             2.0              13.0   \n",
      "2        319.0        336.0             2.0             4.0              11.0   \n",
      "3        408.0        391.0             4.0             2.0              30.0   \n",
      "4        361.0        368.0             0.0             0.0               0.0   \n",
      "5        330.0        356.0             0.0             1.0               0.0   \n",
      "6        213.0        352.0             0.0             3.0               0.0   \n",
      "7        276.0        426.0             3.0             4.0              16.0   \n",
      "8        324.0        368.0             1.0             2.0              11.0   \n",
      "9        425.0        334.0             2.0             3.0              10.0   \n",
      "\n",
      "   yds_sacked_for_H  fumbles_A  fumbles_H  fumbles_lost_A  fumbles_lost_H  \\\n",
      "0               NaN        NaN        NaN             NaN             NaN   \n",
      "1               9.0        1.0        0.0             1.0             0.0   \n",
      "2              17.0        2.0        2.0             0.0             2.0   \n",
      "3              10.0        0.0        0.0             0.0             0.0   \n",
      "4               0.0        2.0        2.0             1.0             0.0   \n",
      "5               7.0        2.0        0.0             0.0             0.0   \n",
      "6              29.0        1.0        0.0             0.0             0.0   \n",
      "7              30.0        2.0        0.0             0.0             0.0   \n",
      "8              14.0        2.0        0.0             1.0             0.0   \n",
      "9              22.0        1.0        1.0             0.0             0.0   \n",
      "\n",
      "   turnovers_A  turnovers_H  penalties_A  penalties_H  penalty_yds_A  \\\n",
      "0          NaN          NaN          NaN          NaN            NaN   \n",
      "1          1.0          1.0          2.0          3.0           15.0   \n",
      "2          0.0          3.0          3.0          8.0           30.0   \n",
      "3          2.0          0.0          5.0          3.0           33.0   \n",
      "4          1.0          0.0          2.0          5.0           15.0   \n",
      "5          2.0          0.0          1.0          6.0            5.0   \n",
      "6          0.0          0.0         11.0          3.0           70.0   \n",
      "7          0.0          0.0          6.0          5.0           54.0   \n",
      "8          2.0          0.0          6.0          2.0           50.0   \n",
      "9          0.0          0.0          4.0          5.0           36.0   \n",
      "\n",
      "   penalty_yds_H  first_downs_A  first_downs_H  third_down_conv_A  \\\n",
      "0            NaN            NaN            NaN                NaN   \n",
      "1           20.0           28.0           23.0                6.0   \n",
      "2           95.0           22.0           16.0                8.0   \n",
      "3           17.0           23.0           26.0                4.0   \n",
      "4           28.0           21.0           27.0                1.0   \n",
      "5           83.0           20.0           19.0                7.0   \n",
      "6           15.0           10.0           22.0                4.0   \n",
      "7           25.0           13.0           23.0                0.0   \n",
      "8           24.0           22.0           24.0                5.0   \n",
      "9           34.0           22.0           23.0                3.0   \n",
      "\n",
      "   third_down_conv_H  third_down_att_A  third_down_att_H  \\\n",
      "0                NaN               NaN               NaN   \n",
      "1                6.0              12.0              12.0   \n",
      "2                3.0              18.0              11.0   \n",
      "3                6.0              12.0              14.0   \n",
      "4                7.0               5.0              14.0   \n",
      "5               10.0              13.0              16.0   \n",
      "6                4.0              12.0              12.0   \n",
      "7                6.0               9.0              14.0   \n",
      "8                5.0              11.0              12.0   \n",
      "9                3.0               9.0               9.0   \n",
      "\n",
      "   third_down_conv_pct_A  third_down_conv_pct_H  fourth_down_conv_A  \\\n",
      "0                    NaN                    NaN                 NaN   \n",
      "1                  0.500                  0.500                 1.0   \n",
      "2                  0.444                  0.273                 1.0   \n",
      "3                  0.333                  0.429                 1.0   \n",
      "4                  0.200                  0.500                 0.0   \n",
      "5                  0.538                  0.625                 0.0   \n",
      "6                  0.333                  0.333                 0.0   \n",
      "7                  0.000                  0.429                 0.0   \n",
      "8                  0.455                  0.417                 0.0   \n",
      "9                  0.333                  0.333                 1.0   \n",
      "\n",
      "   fourth_down_conv_H  fourth_down_att_A  fourth_down_att_H  \\\n",
      "0                 NaN                NaN                NaN   \n",
      "1                 0.0                3.0                1.0   \n",
      "2                 2.0                2.0                2.0   \n",
      "3                 1.0                1.0                1.0   \n",
      "4                 2.0                0.0                3.0   \n",
      "5                 0.0                1.0                0.0   \n",
      "6                 2.0                1.0                2.0   \n",
      "7                 1.0                2.0                2.0   \n",
      "8                 1.0                1.0                1.0   \n",
      "9                 1.0                1.0                1.0   \n",
      "\n",
      "   fourth_down_conv_pct_A  fourth_down_conv_pct_H  time_of_possession_A  \\\n",
      "0                     NaN                     NaN                   NaN   \n",
      "1                   0.333                   0.000                1668.0   \n",
      "2                   0.500                   1.000                2250.0   \n",
      "3                   1.000                   1.000                1680.0   \n",
      "4                   0.000                   0.667                1377.0   \n",
      "5                   0.000                   0.000                1819.0   \n",
      "6                   0.000                   1.000                1345.0   \n",
      "7                   0.000                   0.500                1557.0   \n",
      "8                   0.000                   1.000                1601.0   \n",
      "9                   1.000                   1.000                1805.0   \n",
      "\n",
      "   time_of_possession_H  tot_plays_A  tot_plays_H  total_yds_per_play_A  \\\n",
      "0                   NaN          NaN          NaN                   NaN   \n",
      "1                1932.0         70.0         64.0              6.314286   \n",
      "2                1350.0         71.0         53.0              4.492958   \n",
      "3                1920.0         56.0         69.0              7.285714   \n",
      "4                2223.0         47.0         78.0              7.680851   \n",
      "5                1781.0         62.0         63.0              5.322581   \n",
      "6                2255.0         47.0         64.0              4.531915   \n",
      "7                2043.0         50.0         65.0              5.520000   \n",
      "8                1999.0         62.0         64.0              5.225806   \n",
      "9                1795.0         53.0         52.0              8.018868   \n",
      "\n",
      "   total_yds_per_play_H  points_A  points_H  \n",
      "0                   NaN       NaN       NaN  \n",
      "1              6.453125      31.0      34.0  \n",
      "2              6.339623      17.0      10.0  \n",
      "3              5.666667      23.0      31.0  \n",
      "4              4.717949      27.0      24.0  \n",
      "5              5.650794      21.0      24.0  \n",
      "6              5.500000      10.0      34.0  \n",
      "7              6.553846       9.0      32.0  \n",
      "8              5.750000      17.0      31.0  \n",
      "9              6.423077      23.0      24.0  \n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "print(merged_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a0e63a2-8d21-4a8f-87c7-cda50ea480cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add columns for differentials\n",
    "\n",
    "# Calculate the difference between \"total_yds_A\" and \"total_yds_H\" and store it in a new column\n",
    "merged_df['tot_yds_diff_A'] = merged_df['total_yds_A'] - merged_df['total_yds_H']\n",
    "merged_df['tot_yds_diff_H'] = merged_df['total_yds_H'] - merged_df['total_yds_A']\n",
    "\n",
    "# Calculate the difference between \"rush_yds_A\" and \"rush_yds_H\" and store it in a new column\n",
    "merged_df['rush_yds_diff_A'] = merged_df['rush_yds_A'] - merged_df['rush_yds_H']\n",
    "merged_df['rush_yds_diff_H'] = merged_df['rush_yds_H'] - merged_df['rush_yds_A']\n",
    "\n",
    "# Add columns for turnover differential\n",
    "# Calculate the difference between \"turnovers_A\" and \"turnovers_H\" and store it in a new column\n",
    "merged_df['turnover_diff_A'] = merged_df['turnovers_A'] - merged_df['turnovers_H']\n",
    "merged_df['turnover_diff_H'] = merged_df['turnovers_H'] - merged_df['turnovers_A']\n",
    "\n",
    "# Calculate the difference between \"time_of_possession_A\" and \"time_of_possession_H\" and store it in a new column\n",
    "merged_df['time_poss_diff_A'] = merged_df['time_of_possession_A'] - merged_df['time_of_possession_H']\n",
    "merged_df['time_poss_diff_H'] = merged_df['time_of_possession_H'] - merged_df['time_of_possession_A']\n",
    "\n",
    "# Calculate the difference between \"total_yds_per_play_A\" and \"total_yds_per_play_H\" and store it in a new column\n",
    "merged_df['tot_yds_play_diff_A'] = merged_df['total_yds_per_play_A'] - merged_df['total_yds_per_play_H']\n",
    "merged_df['tot_yds_play_diff_H'] = merged_df['total_yds_per_play_H'] - merged_df['total_yds_per_play_A']\n",
    "\n",
    "# Calculate the difference between \"third_down_conv_pct_A\" and \"third_down_conv_pct_H\" and store it in a new column\n",
    "merged_df['third_down_effic_diff_A'] = merged_df['third_down_conv_pct_A'] - merged_df['third_down_conv_pct_H']\n",
    "merged_df['third_down_effic_diff_H'] = merged_df['third_down_conv_pct_H'] - merged_df['third_down_conv_pct_A']\n",
    "\n",
    "# Calculate the difference between \"Points_A\" and \"Points_H\" and store it in a new column\n",
    "merged_df['point_diff_A'] = merged_df['points_A'] - merged_df['points_H']\n",
    "merged_df['point_diff_H'] = merged_df['points_H'] - merged_df['points_A']\n",
    "\n",
    "# Encode Away team as -1 and Home team as +1\n",
    "merged_df['away'] = -1\n",
    "merged_df['home'] = 1\n",
    "\n",
    "# Encode result of game. -1 for loss. +1 for win. 0 for tie.\n",
    "# Add a new column named \"Result_A\" based on the values of \"Point_diff_A\"\n",
    "merged_df['result_A'] = merged_df['point_diff_A'].apply(lambda x: 1 if x > 0 else (0 if x < 0 else 0))\n",
    "\n",
    "# Add a new column named \"Result_H\" based on the values of \"Point_diff_H\"\n",
    "merged_df['result_H'] = merged_df['point_diff_H'].apply(lambda x: 1 if x > 0 else (0 if x < 0 else 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1314d57-4ca6-4342-9490-51e8c018bd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'name_A' and 'name_H' columns based on 'tm_location'\n",
    "merged_df['name_A'] = np.where(merged_df['tm_location'] == 'H', merged_df['opp_name'], merged_df['tm_name'])\n",
    "merged_df['name_H'] = np.where(merged_df['tm_location'] == 'H', merged_df['tm_name'], merged_df['opp_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24161108-40ef-49d6-bf42-d34a5d4ac86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created 'merged_df.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Save merged_df to a CSV file (excluding index by default)\n",
    "merged_df.to_csv(\"merged_df.csv\", index=False)\n",
    "\n",
    "print(\"Successfully created 'merged_df.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f346592-ec3f-403f-97c2-c14d794ac676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the rows for 'team_df'\n",
    "team_rows = []\n",
    "\n",
    "# Iterate over each row in 'merged_df'\n",
    "for _, row in merged_df.iterrows():\n",
    "    # Create a dictionary to store the team's data\n",
    "    team_data = {\n",
    "        'status': row['status'],\n",
    "        'season': row['season'],\n",
    "        'week': row['week'],\n",
    "        'week_day': row['week_day'],\n",
    "        'event_date': row['event_date'],\n",
    "        'market': row['tm_market'] if (row['result_A'] == 1 and row['tm_location'] == 'A') or (row['result_H'] == 1 and row['tm_location'] == 'H') else row['opp_market'],\n",
    "        'name': row['tm_name'] if (row['result_A'] == 1 and row['tm_location'] == 'A') or (row['result_H'] == 1 and row['tm_location'] == 'H') else row['opp_name'],\n",
    "        'alias': row['tm_alias'] if (row['result_A'] == 1 and row['tm_location'] == 'A') or (row['result_H'] == 1 and row['tm_location'] == 'H') else row['opp_alias'],\n",
    "        'alt_market': row['tm_alt_market'] if (row['result_A'] == 1 and row['tm_location'] == 'A') or (row['result_H'] == 1 and row['tm_location'] == 'H') else row['opp_alt_market'],\n",
    "        'alt_alias': row['tm_alt_alias'] if (row['result_A'] == 1 and row['tm_location'] == 'A') or (row['result_H'] == 1 and row['tm_location'] == 'H') else row['opp_alt_alias'],\n",
    "        'location': row['tm_location'],\n",
    "        'score': row['tm_score'] if (row['result_A'] == 1 and row['tm_location'] == 'A') or (row['result_H'] == 1 and row['tm_location'] == 'H') else row['opp_score'],\n",
    "        'rush_att': row['rush_att_A'] if row['tm_location'] == 'A' else row['rush_att_H'],\n",
    "        'rush_yds': row['rush_yds_A'] if row['tm_location'] == 'A' else row['rush_yds_H'],\n",
    "        'rush_tds': row['rush_tds_A'] if row['tm_location'] == 'A' else row['rush_tds_H'],\n",
    "        'pass_cmp': row['pass_cmp_A'] if row['tm_location'] == 'A' else row['pass_cmp_H'],\n",
    "        'pass_att': row['pass_att_A'] if row['tm_location'] == 'A' else row['pass_att_H'],\n",
    "        'pass_cmp_pct': row['pass_cmp_pct_A'] if row['tm_location'] == 'A' else row['pass_cmp_pct_H'],\n",
    "        'pass_yds': row['pass_yds_A'] if row['tm_location'] == 'A' else row['pass_yds_H'],\n",
    "        'pass_tds': row['pass_tds_A'] if row['tm_location'] == 'A' else row['pass_tds_H'],\n",
    "        'pass_int': row['pass_int_A'] if row['tm_location'] == 'A' else row['pass_int_H'],\n",
    "        'passer_rating': row['passer_rating_A'] if row['tm_location'] == 'A' else row['passer_rating_H'],\n",
    "        'net_pass_yds': row['net_pass_yds_A'] if row['tm_location'] == 'A' else row['net_pass_yds_H'],\n",
    "        'total_yds': row['total_yds_A'] if row['tm_location'] == 'A' else row['total_yds_H'],\n",
    "        'times_sacked': row['times_sacked_A'] if row['tm_location'] == 'A' else row['times_sacked_H'],\n",
    "        'yds_sacked_for': row['yds_sacked_for_A'] if row['tm_location'] == 'A' else row['yds_sacked_for_H'],\n",
    "        'fumbles': row['fumbles_A'] if row['tm_location'] == 'A' else row['fumbles_H'],\n",
    "        'fumbles_lost': row['fumbles_lost_A'] if row['tm_location'] == 'A' else row['fumbles_lost_H'],\n",
    "        'turnovers': row['turnovers_A'] if row['tm_location'] == 'A' else row['turnovers_H'],\n",
    "        'penalties': row['penalties_A'] if row['tm_location'] == 'A' else row['penalties_H'],\n",
    "        'penalty_yds': row['penalty_yds_A'] if row['tm_location'] == 'A' else row['penalty_yds_H'],\n",
    "        'first_downs': row['first_downs_A'] if row['tm_location'] == 'A' else row['first_downs_H'],\n",
    "        'third_down_conv': row['third_down_conv_A'] if row['tm_location'] == 'A' else row['third_down_conv_H'],\n",
    "        'third_down_att': row['third_down_att_A'] if row['tm_location'] == 'A' else row['third_down_att_H'],\n",
    "        'third_down_conv_pct': row['third_down_conv_pct_A'] if row['tm_location'] == 'A' else row['third_down_conv_pct_H'],\n",
    "        'fourth_down_conv': row['fourth_down_conv_A'] if row['tm_location'] == 'A' else row['fourth_down_conv_H'],\n",
    "        'fourth_down_att': row['fourth_down_att_A'] if row['tm_location'] == 'A' else row['fourth_down_att_H'],\n",
    "        'fourth_down_conv_pct': row['fourth_down_conv_pct_A'] if row['tm_location'] == 'A' else row['fourth_down_conv_pct_H'],\n",
    "        'time_of_possession': row['time_of_possession_A'] if row['tm_location'] == 'A' else row['time_of_possession_H'],\n",
    "        'points': row['points_A'] if row['tm_location'] == 'A' else row['points_H'],\n",
    "        'tot_yds_diff': row['tot_yds_diff_A'] if row['tm_location'] == 'A' else row['tot_yds_diff_H'],\n",
    "        'rush_yds_diff': row['rush_yds_diff_A'] if row['tm_location'] == 'A' else row['rush_yds_diff_H'],\n",
    "        'turnover_diff': row['turnover_diff_A'] if row['tm_location'] == 'A' else row['turnover_diff_H'],\n",
    "        'time_poss_diff': row['time_poss_diff_A'] if row['tm_location'] == 'A' else row['time_poss_diff_H'],\n",
    "        'point_diff': row['point_diff_A'] if row['tm_location'] == 'A' else row['point_diff_H'],\n",
    "        'away': row['away'] if (row['result_A'] == 1 and row['tm_location'] == 'A') or (row['result_H'] == 0 and row['tm_location'] == 'H') else row['home'],\n",
    "        'home': row['home'] if (row['result_H'] == 1 and row['tm_location'] == 'H') or (row['result_A'] == 0 and row['tm_location'] == 'A') else row['away'],\n",
    "        'result': 1 if (row['result_A'] == 1 and row['tm_location'] == 'A') or (row['result_H'] == 1 and row['tm_location'] == 'H') else 0,\n",
    "        'tot_plays': row['tot_plays_A'] if row['tm_location'] == 'A' else row['tot_plays_H'],\n",
    "        'total_yds_per_play': row['total_yds_per_play_A'] if row['tm_location'] == 'A' else row['total_yds_per_play_H']\n",
    "\n",
    "    }\n",
    "    # Append the opponent's data to the list of rows\n",
    "    team_rows.append(team_data)\n",
    "\n",
    "# Create the 'team_df' dataframe from the list of rows\n",
    "team_df = pd.DataFrame(team_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "62b39f2d-8758-43ec-a238-fe9cacee6281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the rows for 'team_df'\n",
    "opp_rows = []\n",
    "\n",
    "# Iterate over each row in 'merged_df'\n",
    "for _, row in merged_df.iterrows():\n",
    "    # Create a dictionary to store the team's data\n",
    "    opp_data = {\n",
    "        'status': row['status'],\n",
    "        'season': row['season'],\n",
    "        'week': row['week'],\n",
    "        'week_day': row['week_day'],\n",
    "        'event_date': row['event_date'],\n",
    "        'market': row['opp_market'] if (row['result_A'] == 0 and row['opp_location'] == 'A') or (row['result_H'] == 0 and row['opp_location'] == 'H') else row['tm_market'],\n",
    "        'name': row['opp_name'] if (row['result_A'] == 0 and row['opp_location'] == 'A') or (row['result_H'] == 0 and row['opp_location'] == 'H') else row['tm_name'],\n",
    "        'alias': row['opp_alias'] if (row['result_A'] == 0 and row['opp_location'] == 'A') or (row['result_H'] == 0 and row['opp_location'] == 'H') else row['tm_alias'],\n",
    "        'alt_market': row['opp_alt_market'] if (row['result_A'] == 0 and row['opp_location'] == 'A') or (row['result_H'] == 0 and row['opp_location'] == 'H') else row['tm_alt_market'],\n",
    "        'alt_alias': row['opp_alt_alias'] if (row['result_A'] == 0 and row['opp_location'] == 'A') or (row['result_H'] == 0 and row['opp_location'] == 'H') else row['tm_alt_alias'],\n",
    "        'location': row['opp_location'],\n",
    "        'score': row['opp_score'] if (row['result_A'] == 0 and row['opp_location'] == 'A') or (row['result_H'] == 0 and row['opp_location'] == 'H') else row['tm_score'],\n",
    "        'rush_att': row['rush_att_A'] if row['opp_location'] == 'A' else row['rush_att_H'],\n",
    "        'rush_yds': row['rush_yds_A'] if row['opp_location'] == 'A' else row['rush_yds_H'],\n",
    "        'rush_tds': row['rush_tds_A'] if row['opp_location'] == 'A' else row['rush_tds_H'],\n",
    "        'pass_cmp': row['pass_cmp_A'] if row['opp_location'] == 'A' else row['pass_cmp_H'],\n",
    "        'pass_att': row['pass_att_A'] if row['opp_location'] == 'A' else row['pass_att_H'],\n",
    "        'pass_cmp_pct': row['pass_cmp_pct_A'] if row['opp_location'] == 'A' else row['pass_cmp_pct_H'],\n",
    "        'pass_yds': row['pass_yds_A'] if row['opp_location'] == 'A' else row['pass_yds_H'],\n",
    "        'pass_tds': row['pass_tds_A'] if row['opp_location'] == 'A' else row['pass_tds_H'],\n",
    "        'pass_int': row['pass_int_A'] if row['opp_location'] == 'A' else row['pass_int_H'],\n",
    "        'passer_rating': row['passer_rating_A'] if row['opp_location'] == 'A' else row['passer_rating_H'],\n",
    "        'net_pass_yds': row['net_pass_yds_A'] if row['opp_location'] == 'A' else row['net_pass_yds_H'],\n",
    "        'total_yds': row['total_yds_A'] if row['opp_location'] == 'A' else row['total_yds_H'],\n",
    "        'times_sacked': row['times_sacked_A'] if row['opp_location'] == 'A' else row['times_sacked_H'],\n",
    "        'yds_sacked_for': row['yds_sacked_for_A'] if row['opp_location'] == 'A' else row['yds_sacked_for_H'],\n",
    "        'fumbles': row['fumbles_A'] if row['opp_location'] == 'A' else row['fumbles_H'],\n",
    "        'fumbles_lost': row['fumbles_lost_A'] if row['opp_location'] == 'A' else row['fumbles_lost_H'],\n",
    "        'turnovers': row['turnovers_A'] if row['opp_location'] == 'A' else row['turnovers_H'],\n",
    "        'penalties': row['penalties_A'] if row['opp_location'] == 'A' else row['penalties_H'],\n",
    "        'penalty_yds': row['penalty_yds_A'] if row['opp_location'] == 'A' else row['penalty_yds_H'],\n",
    "        'first_downs': row['first_downs_A'] if row['opp_location'] == 'A' else row['first_downs_H'],\n",
    "        'third_down_conv': row['third_down_conv_A'] if row['opp_location'] == 'A' else row['third_down_conv_H'],\n",
    "        'third_down_att': row['third_down_att_A'] if row['opp_location'] == 'A' else row['third_down_att_H'],\n",
    "        'third_down_conv_pct': row['third_down_conv_pct_A'] if row['opp_location'] == 'A' else row['third_down_conv_pct_H'],\n",
    "        'fourth_down_conv': row['fourth_down_conv_A'] if row['opp_location'] == 'A' else row['fourth_down_conv_H'],\n",
    "        'fourth_down_att': row['fourth_down_att_A'] if row['opp_location'] == 'A' else row['fourth_down_att_H'],\n",
    "        'fourth_down_conv_pct': row['fourth_down_conv_pct_A'] if row['opp_location'] == 'A' else row['fourth_down_conv_pct_H'],\n",
    "        'time_of_possession': row['time_of_possession_A'] if row['opp_location'] == 'A' else row['time_of_possession_H'],\n",
    "        'points': row['points_A'] if row['opp_location'] == 'A' else row['points_H'],\n",
    "        'tot_yds_diff': row['tot_yds_diff_A'] if row['opp_location'] == 'A' else row['tot_yds_diff_H'],\n",
    "        'rush_yds_diff': row['rush_yds_diff_A'] if row['opp_location'] == 'A' else row['rush_yds_diff_H'],\n",
    "        'turnover_diff': row['turnover_diff_A'] if row['opp_location'] == 'A' else row['turnover_diff_H'],\n",
    "        'time_poss_diff': row['time_poss_diff_A'] if row['opp_location'] == 'A' else row['time_poss_diff_H'],\n",
    "        'point_diff': row['point_diff_A'] if row['opp_location'] == 'A' else row['point_diff_H'],\n",
    "        'away': row['away'] if (row['result_A'] == 1 and row['opp_location'] == 'A') or (row['result_H'] == 0 and row['opp_location'] == 'H') else row['home'],\n",
    "        'home': row['home'] if (row['result_H'] == 1 and row['opp_location'] == 'H') or (row['result_A'] == 0 and row['opp_location'] == 'A') else row['away'],\n",
    "        'result': 1 if (row['result_A'] == 1 and row['opp_location'] == 'A') or (row['result_H'] == 1 and row['opp_location'] == 'H') else 0,\n",
    "        'tot_plays': row['tot_plays_A'] if row['opp_location'] == 'A' else row['tot_plays_H'],\n",
    "        'total_yds_per_play': row['total_yds_per_play_A'] if row['opp_location'] == 'A' else row['total_yds_per_play_H']\n",
    "\n",
    "    }\n",
    "    # Append the opponent's data to the list of rows\n",
    "    team_rows.append(opp_data)\n",
    "\n",
    "# Create the 'team_df' dataframe from the list of rows\n",
    "team_df = pd.DataFrame(team_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0736c0e-4111-4caf-a55c-1b0e1af75375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created 'team_df.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Save merged_df to a CSV file (excluding index by default)\n",
    "team_df.to_csv(\"team_df.csv\", index=False)\n",
    "\n",
    "print(\"Successfully created 'team_df.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "884fe292-4574-4061-8d8d-51007576226e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate season to date team averages\n",
    "\n",
    "# Create an empty list to store the dataframes\n",
    "dataframes = []\n",
    "\n",
    "# Get the maximum number of weeks in the 'Week' column\n",
    "max_weeks = team_df['week'].max()\n",
    "\n",
    "# Iterate from weeks 12 to the maximum number of weeks\n",
    "for i in range(12, max_weeks + 1):\n",
    "    # Create a new dataframe by filtering the original team_df\n",
    "    filtered_df = team_df[(team_df['week'] >= 1) & (team_df['week'] <= i)].copy()\n",
    "\n",
    "    # Select the specified columns from the filtered dataframe\n",
    "    new_df = filtered_df[['name', 'rush_yds_diff', 'turnover_diff', 'time_poss_diff', 'point_diff', 'tot_yds_diff','away','home']]\n",
    "\n",
    "    # Append the new dataframe to the list\n",
    "    dataframes.append(new_df)\n",
    "\n",
    "# Assign the dataframes to variables dynamically\n",
    "for i, dataframe in enumerate(dataframes, start=13):\n",
    "    globals()[f\"std{i}_df\"] = dataframe\n",
    "\n",
    "# Calculate the average values for each 'name' in the dataframes\n",
    "team_avg_dfs = []\n",
    "for dataframe in dataframes:\n",
    "    avg_df = dataframe.groupby('name').mean().reset_index()\n",
    "    team_avg_dfs.append(avg_df)\n",
    "\n",
    "# Assign the average dataframes to variables dynamically\n",
    "for i, avg_df in enumerate(team_avg_dfs, start=13):\n",
    "    globals()[f\"team_avg_wk{i}\"] = avg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b801dbf4-f968-45de-9419-41bace077e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created 'team_avg_df.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Save team_avg_df to a CSV file (excluding index by default)\n",
    "team_avg_wk14.to_csv(\"team_avg_df.csv\", index=False)\n",
    "\n",
    "print(\"Successfully created 'team_avg_df.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "20a5c256-18b1-47d3-a799-4ab18367eed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the head to head matchups and load the season to date averages as the Kahn features.\n",
    "\n",
    "# Create an empty list to store the dataframes\n",
    "dataframes = []\n",
    "\n",
    "# Iterate over weeks 13 to max_weeks\n",
    "for week in range(13, max_weeks + 1):\n",
    "    # Filter the dataframe for rows where 'Week' column is equal to the current week\n",
    "    filtered_df = merged_df[merged_df['week'] == week].copy()  # Use .copy() to avoid SettingWithCopyWarning\n",
    "    \n",
    "    # Select the specified columns from the filtered dataframe\n",
    "    selected_columns = ['week', 'name_A','name_H', 'result_A','result_H', 'points_A', 'points_H', 'away', 'home']\n",
    "    new_df = filtered_df[selected_columns].copy()  # Make a copy to avoid SettingWithCopyWarning\n",
    "    \n",
    "    # Add the new columns with NaN values using .loc and appending '_A' or '_H' to each column name\n",
    "    new_columns = ['rush_yds_diff_A', 'turnover_diff_A', 'time_poss_diff_A', 'Point_diff_A', 'tot_yds_diff_A',\n",
    "                   'rush_yds_diff_H', 'turnover_diff_H', 'time_poss_diff_H', 'Point_diff_H', 'tot_yds_diff_H']\n",
    "    for col in new_columns:\n",
    "        new_df.loc[:, col] = np.nan  # Use .loc to assign NaN values to the new columns\n",
    "    \n",
    "    # Append the new dataframe to the list\n",
    "    dataframes.append(new_df)\n",
    "\n",
    "# Assign the dataframes to variables dynamically\n",
    "for i, dataframe in enumerate(dataframes, start=14):\n",
    "    globals()[f\"week{i}_df\"] = dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2029fd3a-8ed9-40d6-9e05-eef5dea2cd6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created 'week14_df.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Save week14_df to a CSV file (excluding index by default)\n",
    "week14_df.to_csv(\"week14_df.csv\", index=False)\n",
    "\n",
    "print(\"Successfully created 'week14_df.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bda69095-1b01-4fb5-bc43-49e87c3372d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build training set\n",
    "train_df = merged_df.loc[(merged_df['week'] >= 1) & (merged_df['week'] <= 12), ['tot_yds_diff_A', 'rush_yds_diff_A', 'time_poss_diff_A', 'turnover_diff_A', 'away', 'tot_yds_diff_H', 'rush_yds_diff_H', 'time_poss_diff_H', 'turnover_diff_H', 'home', 'result_A', 'result_H']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "18a79c18-bc31-4a2a-8ecf-6afd697f803f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Loss: 0.5135\n",
      "Epoch [20/50], Loss: 0.4076\n",
      "Epoch [30/50], Loss: 0.3611\n",
      "Epoch [40/50], Loss: 0.3450\n",
      "Epoch [50/50], Loss: 0.3389\n"
     ]
    }
   ],
   "source": [
    "# train model on away data\n",
    "# Separate features and target\n",
    "X_train_A = train_df[['tot_yds_diff_A', 'rush_yds_diff_A', 'time_poss_diff_A', 'turnover_diff_A', 'away']].values\n",
    "y_train_A = train_df['result_A'].values\n",
    "\n",
    "# Standardize the features\n",
    "scaler_A = StandardScaler()\n",
    "X_train_A = scaler_A.fit_transform(X_train_A)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_A = torch.from_numpy(X_train_A).float()\n",
    "y_train_A = torch.from_numpy(y_train_A).long()\n",
    "\n",
    "# Define the MLP model\n",
    "class MLP_A(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MLP_A, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "input_size_A = X_train_A.shape[1]\n",
    "hidden_size_A = 32\n",
    "output_size_A = 2  # Binary classification for \"Result-A\"\n",
    "model_A = MLP_A(input_size_A, hidden_size_A, output_size_A)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion_A = nn.CrossEntropyLoss()\n",
    "optimizer_A = optim.Adam(model_A.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "num_epochs_A = 50\n",
    "for epoch in range(num_epochs_A):\n",
    "    # Forward pass\n",
    "    outputs_A = model_A(X_train_A)\n",
    "    loss_A = criterion_A(outputs_A, y_train_A)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer_A.zero_grad()\n",
    "    loss_A.backward()\n",
    "    optimizer_A.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs_A}], Loss: {loss_A.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c7cb448b-be75-44b8-b79f-c22f00277bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Loss: 0.4581\n",
      "Epoch [20/50], Loss: 0.3888\n",
      "Epoch [30/50], Loss: 0.3607\n",
      "Epoch [40/50], Loss: 0.3496\n",
      "Epoch [50/50], Loss: 0.3401\n"
     ]
    }
   ],
   "source": [
    "# train model on home data\n",
    "# Preprocess the target values\n",
    "train_df['result_H'] = train_df['result_H'].replace({-1: 0})\n",
    "\n",
    "# Separate features and target\n",
    "X_train_H = train_df[['tot_yds_diff_H', 'rush_yds_diff_H', 'time_poss_diff_H', 'turnover_diff_H', 'home']].values\n",
    "y_train_H = train_df['result_H'].values\n",
    "\n",
    "# Standardize the features\n",
    "scaler_H = StandardScaler()\n",
    "X_train_H = scaler_H.fit_transform(X_train_H)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_H = torch.from_numpy(X_train_H).float()\n",
    "y_train_H = torch.from_numpy(y_train_H).long()\n",
    "\n",
    "# Define the MLP model\n",
    "class MLP_H(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MLP_H, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "input_size_H = X_train_H.shape[1]\n",
    "hidden_size_H = 32\n",
    "output_size_H = 2  # Binary classification for \"Result-H\"\n",
    "model_H = MLP_H(input_size_H, hidden_size_H, output_size_H)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion_H = nn.CrossEntropyLoss()\n",
    "optimizer_H = optim.Adam(model_H.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "num_epochs_H = 50\n",
    "for epoch in range(num_epochs_H):\n",
    "    # Forward pass\n",
    "    outputs_H = model_H(X_train_H)\n",
    "    loss_H = criterion_H(outputs_H, y_train_H)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer_H.zero_grad()\n",
    "    loss_H.backward()\n",
    "    optimizer_H.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs_H}], Loss: {loss_H.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f135af7c-a258-4c50-8913-63730b2103be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build test set\n",
    "test_df = merged_df.loc[(merged_df['week'] >= 14) & (merged_df['week'] <= 18), ['tot_yds_diff_A', 'rush_yds_diff_A', 'time_poss_diff_A', 'turnover_diff_A', 'away', 'tot_yds_diff_H', 'rush_yds_diff_H', 'time_poss_diff_H', 'turnover_diff_H', 'home', 'result_A', 'result_H']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40c88d8-3c70-42d9-b146-771e732658e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e5c07cd8-8b97-419d-bbe9-c99ae65c20bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Test Accuracy for Week 14: 0.4000\n",
      "Combined Predictions:\n",
      "Away Team: Packers, Home Team: Giants, Actual Winner: 0, Predicted Winner: 1\n",
      "Away Team: Titans, Home Team: Dolphins, Actual Winner: 1, Predicted Winner: 0\n",
      "Away Team: Seahawks, Home Team: 49ers, Actual Winner: 0, Predicted Winner: 0\n",
      "Away Team: Broncos, Home Team: Chargers, Actual Winner: 1, Predicted Winner: 0\n",
      "Away Team: Rams, Home Team: Ravens, Actual Winner: 0, Predicted Winner: 0\n",
      "Away Team: Vikings, Home Team: Raiders, Actual Winner: 1, Predicted Winner: 1\n",
      "Away Team: Texans, Home Team: Jets, Actual Winner: 0, Predicted Winner: 1\n",
      "Away Team: Panthers, Home Team: Saints, Actual Winner: 0, Predicted Winner: 0\n",
      "Away Team: Bills, Home Team: Chiefs, Actual Winner: 1, Predicted Winner: 0\n",
      "Away Team: Eagles, Home Team: Cowboys, Actual Winner: 0, Predicted Winner: 0\n",
      "Away Team: Jaguars, Home Team: Browns, Actual Winner: 0, Predicted Winner: 0\n",
      "Away Team: Colts, Home Team: Bengals, Actual Winner: 0, Predicted Winner: 1\n",
      "Away Team: Lions, Home Team: Bears, Actual Winner: 0, Predicted Winner: 1\n",
      "Away Team: Buccaneers, Home Team: Falcons, Actual Winner: 1, Predicted Winner: 0\n",
      "Away Team: Patriots, Home Team: Steelers, Actual Winner: 1, Predicted Winner: 0\n",
      "\n",
      "Combined Test Accuracy for Week 15: 0.8125\n",
      "Combined Predictions:\n",
      "Away Team: Eagles, Home Team: Seahawks, Actual Winner: 0, Predicted Winner: 0\n",
      "Away Team: Football Team, Home Team: Rams, Actual Winner: 0, Predicted Winner: 0\n",
      "Away Team: Texans, Home Team: Titans, Actual Winner: 1, Predicted Winner: 1\n",
      "Away Team: Chiefs, Home Team: Patriots, Actual Winner: 1, Predicted Winner: 1\n",
      "Away Team: Giants, Home Team: Saints, Actual Winner: 0, Predicted Winner: 0\n",
      "Away Team: Jets, Home Team: Dolphins, Actual Winner: 0, Predicted Winner: 0\n",
      "Away Team: Ravens, Home Team: Jaguars, Actual Winner: 1, Predicted Winner: 1\n",
      "Away Team: Buccaneers, Home Team: Packers, Actual Winner: 1, Predicted Winner: 0\n",
      "Away Team: 49ers, Home Team: Cardinals, Actual Winner: 1, Predicted Winner: 1\n",
      "Away Team: Bears, Home Team: Browns, Actual Winner: 0, Predicted Winner: 0\n",
      "Away Team: Falcons, Home Team: Panthers, Actual Winner: 0, Predicted Winner: 1\n",
      "Away Team: Cowboys, Home Team: Bills, Actual Winner: 0, Predicted Winner: 0\n",
      "Away Team: Broncos, Home Team: Lions, Actual Winner: 0, Predicted Winner: 0\n",
      "Away Team: Steelers, Home Team: Colts, Actual Winner: 0, Predicted Winner: 0\n",
      "Away Team: Vikings, Home Team: Bengals, Actual Winner: 0, Predicted Winner: 0\n",
      "Away Team: Chargers, Home Team: Raiders, Actual Winner: 0, Predicted Winner: 1\n",
      "\n",
      "Combined Test Accuracy for Week 16: 0.6250\n",
      "Combined Predictions:\n",
      "Away Team: Ravens, Home Team: 49ers, Actual Winner: 1, Predicted Winner: 0\n",
      "Away Team: Giants, Home Team: Eagles, Actual Winner: 0, Predicted Winner: 0\n",
      "Away Team: Raiders, Home Team: Chiefs, Actual Winner: 1, Predicted Winner: 0\n",
      "Away Team: Jaguars, Home Team: Buccaneers, Actual Winner: 0, Predicted Winner: 0\n",
      "Away Team: Seahawks, Home Team: Titans, Actual Winner: 1, Predicted Winner: 0\n",
      "Away Team: Football Team, Home Team: Jets, Actual Winner: 0, Predicted Winner: 0\n",
      "Away Team: Lions, Home Team: Vikings, Actual Winner: 1, Predicted Winner: 0\n",
      "Away Team: Cowboys, Home Team: Dolphins, Actual Winner: 0, Predicted Winner: 0\n",
      "Away Team: Browns, Home Team: Texans, Actual Winner: 1, Predicted Winner: 0\n",
      "Away Team: Patriots, Home Team: Broncos, Actual Winner: 1, Predicted Winner: 0\n",
      "Away Team: Cardinals, Home Team: Bears, Actual Winner: 0, Predicted Winner: 0\n",
      "Away Team: Packers, Home Team: Panthers, Actual Winner: 1, Predicted Winner: 1\n",
      "Away Team: Colts, Home Team: Falcons, Actual Winner: 0, Predicted Winner: 0\n",
      "Away Team: Bills, Home Team: Chargers, Actual Winner: 1, Predicted Winner: 1\n",
      "Away Team: Bengals, Home Team: Steelers, Actual Winner: 0, Predicted Winner: 0\n",
      "Away Team: Saints, Home Team: Rams, Actual Winner: 0, Predicted Winner: 0\n",
      "\n",
      "Combined Test Accuracy for Week 17: 0.7500\n",
      "Combined Predictions:\n",
      "Away Team: 49ers, Home Team: Football Team, Actual Winner: 1, Predicted Winner: 1\n",
      "Away Team: Saints, Home Team: Buccaneers, Actual Winner: 1, Predicted Winner: 0\n",
      "Away Team: Steelers, Home Team: Seahawks, Actual Winner: 1, Predicted Winner: 0\n",
      "Away Team: Dolphins, Home Team: Ravens, Actual Winner: 0, Predicted Winner: 0\n",
      "Away Team: Cardinals, Home Team: Eagles, Actual Winner: 1, Predicted Winner: 0\n",
      "Away Team: Rams, Home Team: Giants, Actual Winner: 1, Predicted Winner: 1\n",
      "Away Team: Packers, Home Team: Vikings, Actual Winner: 1, Predicted Winner: 0\n",
      "Away Team: Bengals, Home Team: Chiefs, Actual Winner: 0, Predicted Winner: 0\n",
      "Away Team: Panthers, Home Team: Jaguars, Actual Winner: 0, Predicted Winner: 0\n",
      "Away Team: Titans, Home Team: Texans, Actual Winner: 0, Predicted Winner: 0\n",
      "Away Team: Chargers, Home Team: Broncos, Actual Winner: 0, Predicted Winner: 0\n",
      "Away Team: Raiders, Home Team: Colts, Actual Winner: 0, Predicted Winner: 0\n",
      "Away Team: Falcons, Home Team: Bears, Actual Winner: 0, Predicted Winner: 0\n",
      "Away Team: Patriots, Home Team: Bills, Actual Winner: 0, Predicted Winner: 0\n",
      "Away Team: Lions, Home Team: Cowboys, Actual Winner: 0, Predicted Winner: 0\n",
      "Away Team: Jets, Home Team: Browns, Actual Winner: 0, Predicted Winner: 0\n",
      "\n",
      "Combined Test Accuracy for Week 18: 0.5625\n",
      "Combined Predictions:\n",
      "Away Team: Cowboys, Home Team: Football Team, Actual Winner: 1, Predicted Winner: 1\n",
      "Away Team: Rams, Home Team: 49ers, Actual Winner: 1, Predicted Winner: 0\n",
      "Away Team: Chiefs, Home Team: Chargers, Actual Winner: 1, Predicted Winner: 1\n",
      "Away Team: Broncos, Home Team: Raiders, Actual Winner: 0, Predicted Winner: 0\n",
      "Away Team: Jaguars, Home Team: Titans, Actual Winner: 0, Predicted Winner: 0\n",
      "Away Team: Eagles, Home Team: Giants, Actual Winner: 0, Predicted Winner: 1\n",
      "Away Team: Jets, Home Team: Patriots, Actual Winner: 1, Predicted Winner: 0\n",
      "Away Team: Falcons, Home Team: Saints, Actual Winner: 0, Predicted Winner: 0\n",
      "Away Team: Bills, Home Team: Dolphins, Actual Winner: 1, Predicted Winner: 0\n",
      "Away Team: Bears, Home Team: Packers, Actual Winner: 0, Predicted Winner: 0\n",
      "Away Team: Vikings, Home Team: Lions, Actual Winner: 0, Predicted Winner: 0\n",
      "Away Team: Seahawks, Home Team: Cardinals, Actual Winner: 1, Predicted Winner: 1\n",
      "Away Team: Browns, Home Team: Bengals, Actual Winner: 0, Predicted Winner: 1\n",
      "Away Team: Buccaneers, Home Team: Panthers, Actual Winner: 1, Predicted Winner: 1\n",
      "Away Team: Steelers, Home Team: Ravens, Actual Winner: 1, Predicted Winner: 0\n",
      "Away Team: Texans, Home Team: Colts, Actual Winner: 1, Predicted Winner: 0\n",
      "\n",
      "Combined Test Accuracy for Week 19: 0.6667\n",
      "Combined Predictions:\n",
      "Away Team: Eagles, Home Team: Buccaneers, Actual Winner: 0, Predicted Winner: 0\n",
      "Away Team: Steelers, Home Team: Bills, Actual Winner: 0, Predicted Winner: 0\n",
      "Away Team: Rams, Home Team: Lions, Actual Winner: 0, Predicted Winner: 0\n",
      "Away Team: Packers, Home Team: Cowboys, Actual Winner: 1, Predicted Winner: 0\n",
      "Away Team: Dolphins, Home Team: Chiefs, Actual Winner: 0, Predicted Winner: 1\n",
      "Away Team: Browns, Home Team: Texans, Actual Winner: 0, Predicted Winner: 0\n",
      "\n",
      "Combined Test Accuracy for Week 20: 0.7500\n",
      "Combined Predictions:\n",
      "Away Team: Buccaneers, Home Team: Lions, Actual Winner: 0, Predicted Winner: 0\n",
      "Away Team: Chiefs, Home Team: Bills, Actual Winner: 1, Predicted Winner: 0\n",
      "Away Team: Packers, Home Team: 49ers, Actual Winner: 0, Predicted Winner: 0\n",
      "Away Team: Texans, Home Team: Ravens, Actual Winner: 0, Predicted Winner: 0\n",
      "\n",
      "Combined Test Accuracy for Week 21: 0.5000\n",
      "Combined Predictions:\n",
      "Away Team: Lions, Home Team: 49ers, Actual Winner: 0, Predicted Winner: 0\n",
      "Away Team: Chiefs, Home Team: Ravens, Actual Winner: 1, Predicted Winner: 0\n",
      "\n",
      "Combined Test Accuracy for Week 22: 1.0000\n",
      "Combined Predictions:\n",
      "Away Team: Chiefs, Home Team: 49ers, Actual Winner: 0, Predicted Winner: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test weeks 14-max_weeks by predicting outcome using season to date averages\n",
    "# List of dataframes and corresponding team average dataframes\n",
    "df_list = dataframes[1:]  # Assuming dataframes list starts from week 13\n",
    "team_avg_list = [globals()[f\"team_avg_wk{i}\"] for i in range(13, max_weeks)]\n",
    "\n",
    "# Iterate over the dataframes\n",
    "for i in range(len(df_list)):\n",
    "    df = df_list[i]\n",
    "    team_avg_df = team_avg_list[i]\n",
    "\n",
    "    # Populate columns for away team\n",
    "    df['rush_yds_diff_A'] = df['name_A'].map(team_avg_df.set_index('name')['rush_yds_diff'])\n",
    "    df['turnover_diff_A'] = df['name_A'].map(team_avg_df.set_index('name')['turnover_diff'])\n",
    "    df['time_poss_diff_A'] = df['name_A'].map(team_avg_df.set_index('name')['time_poss_diff'])\n",
    "    df['Point_diff_A'] = df['name_A'].map(team_avg_df.set_index('name')['point_diff'])\n",
    "    df['tot_yds_diff_A'] = df['name_A'].map(team_avg_df.set_index('name')['tot_yds_diff'])\n",
    "\n",
    "    # Populate columns for home team\n",
    "    df['rush_yds_diff_H'] = df['name_H'].map(team_avg_df.set_index('name')['rush_yds_diff'])\n",
    "    df['turnover_diff_H'] = df['name_H'].map(team_avg_df.set_index('name')['turnover_diff'])\n",
    "    df['time_poss_diff_H'] = df['name_H'].map(team_avg_df.set_index('name')['time_poss_diff'])\n",
    "    df['Point_diff_H'] = df['name_H'].map(team_avg_df.set_index('name')['point_diff'])\n",
    "    df['tot_yds_diff_H'] = df['name_H'].map(team_avg_df.set_index('name')['tot_yds_diff'])\n",
    "\n",
    "\n",
    "    # Separate features and targets for model A\n",
    "    X_test_A = df[['tot_yds_diff_A', 'rush_yds_diff_A', 'time_poss_diff_A', 'turnover_diff_A', 'away']].values\n",
    "    y_test_A = df['result_A'].values\n",
    "    name_A = df['name_A'].values\n",
    "    name_H = df['name_H'].values\n",
    "\n",
    "    # Standardize the features for model A using the scaler from training\n",
    "    X_test_A = scaler_A.transform(X_test_A)\n",
    "\n",
    "    # Convert data to PyTorch tensors for model A\n",
    "    X_test_A = torch.from_numpy(X_test_A).float()\n",
    "    y_test_A = torch.from_numpy(y_test_A).long()\n",
    "\n",
    "    # Separate features and targets for model H\n",
    "    X_test_H = df[['tot_yds_diff_H', 'rush_yds_diff_H', 'time_poss_diff_H', 'turnover_diff_H', 'home']].values\n",
    "    y_test_H = df['result_H'].values\n",
    "\n",
    "    # Standardize the features for model H using the scaler from training\n",
    "    X_test_H = scaler_H.transform(X_test_H)\n",
    "\n",
    "    # Convert data to PyTorch tensors for model H\n",
    "    X_test_H = torch.from_numpy(X_test_H).float()\n",
    "    y_test_H = torch.from_numpy(y_test_H).long()\n",
    "\n",
    "    # Evaluate models on the test data and combine predictions\n",
    "    with torch.no_grad():\n",
    "        outputs_A = model_A(X_test_A)\n",
    "        outputs_H = model_H(X_test_H)\n",
    "        \n",
    "        _, predicted_A = torch.max(outputs_A, 1)\n",
    "        _, predicted_H = torch.max(outputs_H, 1)\n",
    "        \n",
    "        combined_predictions = torch.where(outputs_A[:, 1] > outputs_H[:, 1], torch.ones_like(predicted_A), torch.zeros_like(predicted_A))\n",
    "        \n",
    "        actual_winners = torch.where(y_test_A == 1, torch.ones_like(y_test_A), torch.zeros_like(y_test_A))\n",
    "        accuracy = (combined_predictions == actual_winners).sum().item() / len(actual_winners)\n",
    "        \n",
    "        print(f'Combined Test Accuracy for Week {i+14}: {accuracy:.4f}')\n",
    "        print('Combined Predictions:')\n",
    "        for j in range(len(y_test_A)):\n",
    "            print(f'Away Team: {name_A[j]}, Home Team: {name_H[j]}, Actual Winner: {actual_winners[j].item()}, Predicted Winner: {combined_predictions[j].item()}')\n",
    "    \n",
    "    print()  # Add a blank line between weeks for readability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80b9076-28fd-418a-95d5-eb2bdf32f880",
   "metadata": {},
   "source": [
    "###### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
